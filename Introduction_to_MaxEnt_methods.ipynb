{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOW017MV7MUlrBuok16L3JQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiguelAguilera/Neuro-MaxEnt-inference-tutorial/blob/main/Introduction_to_MaxEnt_methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Most patterns in biology arise from aggregation of many small processes. Variations in the dynamics of complex neural and biochemical networks depend on\n",
        "numerous fluctuations in connectivity and flow through small-scale subcomponents of the network. Variations in cancer onset arise from variable failures in the many individual checks and balances on DNA repair, cell cycle control, and tissue homeostasis. Variations in the ecological distribution of species follow the myriad local differences in the birth and death rates of species and in the small-scale interactions between particular species.\n",
        "In all such complex systems, we wish to understand how large-scale pattern\n",
        "arises from the aggregation of small-scale processes. A single dominant principle sets the major axis from which all explanation of aggregation and scale must be developed. This dominant principle is the limiting distribution.\n",
        "\n",
        "### A new kind of prior information\n",
        "\n",
        "Imagine a class of problems in which our prior information consists of average\n",
        "values of certain things. What is the less biased model?\n",
        "\n",
        "The notion of ‘entropy’ as originated in thermodynamics is usually associated to that of ‘disorder’ by saying that the former can be regarded as a measure of the latter. The word ‘disorder’ here essentially means ‘randomness’, ‘absence of patterns’, or something similar. While not incorrect, these words clearly require a more precise specification to be useful at a quantitative level. \n",
        "\n",
        "$$ S = - \\sum_{\\mathbf x} p_{\\mathbf x} \\log p_{\\mathbf x}$$\n",
        "\n",
        "We have a total amount of probability\n",
        "$$ \\sum_{\\mathbf x} p_{\\mathbf x}= 1$$\n",
        "\n",
        "![Google's logo](https://www.google.com/images/logos/google_logo_41.png)\n",
        "\n",
        "### Lagrangian multiplier techinque\n",
        "\n",
        "The maximum entropy principle is a means of deriving probability distributions given certain constraints and the assumption of maximizing entropy. One technique for solving this maximization problem is the Lagrange multiplier technique.\n",
        "\n",
        "Given a multivariable function $f(x,y,...)$ and constraints of the form $g(x,y,...)=c$, where $g$ is another multivariable function with the same input space as $f$ and $c$\n",
        "\n",
        "is a constant:\n",
        "\n",
        "In order to minimize (or maximize) the function $f$ consider the following steps, assuming $f$ to be $f(x)$:\n",
        "\n",
        "1. Introduce a new variable $\\lambda$, called Lagrange multiplier, and define a new function $\\mathcal{L}$  with the form:\n",
        "\n",
        "$$ L(x,\\lambda)=f(x)+\\lambda(g(x)−c)$$\n",
        "\n",
        "2. Set the derivative of the function  $\\mathcal{L}$  equal to zero:\n",
        "\n",
        "$$L′(x,λ)=0,$$\n",
        "\n",
        "in order to find the critical points of  $\\mathcal{L}$.\n",
        "\n",
        "3. Consider each resulting solution within the limits of the made constraints and derive the resulting distribution $f$, which gives the minimum (or maximum) one is searching for.\n",
        "\n"
      ],
      "metadata": {
        "id": "hhVIZjR1ykUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example\n",
        "\n",
        "$$ \\mathcal{L} =  -\\sum_{\\mathbf x} p_{\\mathbf x} \\log p_{\\mathbf x}  - \\varphi (\\sum_{\\mathbf x}p_{\\mathbf x} - 1) + \\beta \\sum_a \\theta_a(\\sum_i p_i f_{i,a}-c_a)$$\n",
        "\n",
        "$$  \\frac{\\mathrm{d}\\mathcal{L}}{\\mathrm{d}p_i} =  - 1 - \\log p_{\\mathbf x}\n",
        "- \\varphi  +  \\beta \\sum_a \\theta_a f_{\\mathbf x,a}=0 $$\n",
        "\n",
        "$$ p_{\\mathbf x} \\propto \\exp\\left[\\beta \\sum_a \\theta_a f_{\\mathbf x,a} - \\varphi \\right] $$\n",
        "\n",
        "\n",
        "$$ p_{\\mathbf x} \\propto \\frac{1}{Z}\\exp\\left[\\beta \\sum_a \\theta_a f_{\\mathbf x,a} \\right] $$"
      ],
      "metadata": {
        "id": "vqRimQ7xGQz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### References\n",
        "\n",
        "J. Harte, Maximum Entropy and Ecology: A Theory of Abundance, Distribution, and Energetics. Oxford University Press, 2011\n",
        "\n",
        "E. Montrell, On the entropy function in sociotechnical systems, PNAS, vol. 78 no. 12, 1981\n",
        "\n",
        "S. Frank, The common patterns of nature\n",
        "\n",
        "Academy, Khan. 2019. “Lagrange multipliers, introduction.” 2019. https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/constrained-optimization/a/lagrange-multipliers-single-constraint."
      ],
      "metadata": {
        "id": "056AazBwGNfm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8splVbnyjyd"
      },
      "outputs": [],
      "source": []
    }
  ]
}